{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a863db72-761f-47ca-9899-644d87587b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from srn_data_collector.parse_esrs_requirements.parse_esrs_for_rag import parse_data\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e188335-82a9-4f63-b68c-d06f585e83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pth = open('/home/ppradhan/openai.txt')\n",
    "ls_file = open('/home/ppradhan/langsmith.txt')\n",
    "os.environ[\"OPENAI_API_KEY\"] = file_pth.read().strip()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = ls_file.read().strip()\n",
    "\n",
    "#cuBLAS settings for llama inference\n",
    "os.environ[\"CMAKE_ARGS\"] = \"-DLLAMA_BLAS=on -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
    "os.environ[\"FORCE_CMAKE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca90f3e3-ae7a-478b-af7e-93cd2de0f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ppradhan/Documents/my_dev/esrs_data_collection/srn_data_collector/data-analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2725ae-5bff-4bb9-ab70-7a39b3570faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "esrs_parsed_json = '../parse_esrs_requirements/esrs_requirement_main.json'\n",
    "esrs_sample_json = '../parse_esrs_requirements/query_req_data.json'\n",
    "# recommendation_response_path = '/cluster/home/srn_storage/sample_retriever_recommendations'\n",
    "sample_pdf_raw_parsed_json_path = 'sample_raw_pdf.json'\n",
    "sample_pdf_formatted_path = '../parse_esrs_requirements/docu_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f73efc-34d2-4c76-83b1-c139014c2803",
   "metadata": {},
   "source": [
    "### Loading requirements into vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effc120-0037-4bc1-82d1-102d863c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esrs_parsed = parse_data(esrs_parsed_json)\n",
    "# with open(esrs_sample_json, 'w') as f:\n",
    "#     json.dump(esrs_parsed,f)\n",
    "\n",
    "# esrs_parsed\n",
    "\n",
    "# esrs_parsed.keys()\n",
    "\n",
    "# main_categories_map = {\"environmental\": ['climate change', 'pollution', 'water and marine resources', 'biodiversity and ecosystems'],\n",
    "#                       \"social\": ['circular economy', 'own workforce', 'workers in the value chain', 'affected communities', 'consumers and end-users'],\n",
    "#                       \"global\" : [\"business conduct\"]}\n",
    "\n",
    "# def q_builder_metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "#     metadata[\"label\"] = record.get(\"label\")\n",
    "\n",
    "#     return metadata\n",
    "\n",
    "# loader = JSONLoader(\n",
    "#     file_path=esrs_sample_json,\n",
    "#     jq_schema=' .\"climate change\"[], .\"own workforce\"[], .\"business conduct\"[]',\n",
    "#     text_content=False,\n",
    "#     content_key='text',\n",
    "#     metadata_func=q_builder_metadata_func)\n",
    "\n",
    "# query_data = loader.load()\n",
    "\n",
    "# len(query_data)\n",
    "\n",
    "# query_data[0].page_content\n",
    "\n",
    "# query_data[0].metadata\n",
    "\n",
    "# # text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# # splits_query = text_splitter.split_documents(query_data)\n",
    "# # vectorstore_query = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "# vectorstore_query = Chroma.from_documents(documents=query_data, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# # Retrieve and generate using the relevant snippets of the blog.\n",
    "# query_retriever = vectorstore_query.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# query_retriever.invoke(\"Query about Climate change, GHG emissions\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c71618-a2f1-4806-9bea-70def438861c",
   "metadata": {},
   "source": [
    "### Loading entire document in vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c8f2f1-be06-441b-bbdc-13ee1d0871d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_pdf_raw_parsed_json_path, 'r') as f:\n",
    "    sample_doc_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49affb87-87e7-4262-bc02-18fdc538e44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_formatted_data = {\"doc_data\" : []}\n",
    "for doc_ref, blob_list in sample_doc_dict.items():\n",
    "    for blob_id, blob_data in enumerate(blob_list):\n",
    "        doc_formatted_data['doc_data'].append({\"text\": blob_data['text'], \"blob_id\": blob_id, \"doc_ref\": doc_ref})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac6e1c7-9722-4533-8178-194607c0a65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(sample_pdf_formatted_path, 'w') as f:\n",
    "    json.dump(doc_formatted_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffe98b9-6dce-433e-8eb6-2f220958a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    metadata[\"blob_id\"] = record.get(\"blob_id\")\n",
    "    metadata[\"doc_ref\"] = record.get(\"doc_ref\")\n",
    "\n",
    "    # if \"source\" in metadata:\n",
    "    #     source = metadata[\"source\"].split(\"/\")\n",
    "    #     source = source[source.index(\"langchain\"):]\n",
    "    #     metadata[\"source\"] = \"/\".join(source)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efce9194-068e-4f1b-aeac-b72c29845e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_loader = JSONLoader(\n",
    "    file_path=sample_pdf_formatted_path,\n",
    "    jq_schema='.doc_data[]',\n",
    "    text_content=False,\n",
    "    content_key='text',\n",
    "    metadata_func=metadata_func)\n",
    "\n",
    "doc_data = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e49dd51-9644-4bdf-b302-f8f748739ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits_doc = text_splitter.split_documents(doc_data)\n",
    "vectorstore_doc = Chroma.from_documents(documents=splits_doc, embedding=OpenAIEmbeddings())\n",
    "vectorstore_doc = Chroma.from_documents(documents=doc_data, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever_doc = vectorstore_doc.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc3b0e7-4f95-4f99-baf6-2b55bcec882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='202\\nANNUAL \\nREPORT', metadata={'source': '/home/ppradhan/Documents/my_dev/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json', 'seq_num': 1, 'blob_id': 0, 'doc_ref': '1'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb71b4-3348-4a89-8763-7f9556e3a808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2fb09-be2b-408f-9ae3-cef48ca0de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt template \n",
    "sample_requirement = \"\"\"\n",
    "AR 43. When preparing the information on gross Scope 2 GHG emissions required under \n",
    "paragraph 46, the undertaking shall:\n",
    "(a) consider the principles and requirements of the GHG Protocol Scope 2 Guidance \n",
    "(version 2015 or the latest one); it may also consider corresponding requirements \n",
    "for the quantification of indirect GHG emissions from imported energy in ISO \n",
    "14064-1:2018;\n",
    "(b) include purchased or acquired electricity, steam, heat, and cooling consumed by \n",
    "the undertaking; \n",
    "(c) avoid double counting of GHG emissions reported under Scope 1 or 3;\n",
    "(d) apply the location-based and market-based methods to calculate Scope 2 GHG \n",
    "emissions;\n",
    "Note: Location-based method quantifies Scope 2 GHG emissions based on \n",
    "average energy generation emission factors for defined locations, including local, \n",
    "subnational, or national boundaries (GHG Protocol, �Scope 2 Guidance�, \n",
    "Glossary, 2015);\n",
    "Note: Market-based method quantifies Scope 2 GHG emissions based on GHG \n",
    "emissions emitted by the generators from which the reporting entity contractually \n",
    "purchases electricity bundled with instruments, or unbundled instruments on their \n",
    "own (GHG Protocol, �Scope 2 Guidance�, Glossary, 2015); in this case, the \n",
    "undertaking may disclose the share of market-based scope 2 GHG emissions \n",
    "linked to purchased electricity bundled with instruments such as Guarantee of \n",
    "Origins or Renewable Energy Certificates.\n",
    "(e) disclose biogenic emissions of carbon from the combustion or biodegradation of \n",
    "biomass separately from the Scope 2 GHG emissions but include emissions of \n",
    "other types of GHG (in particular N2O). In case the emission factors applied do \n",
    "not separate the percentage of biomass or biogenic CO2, the undertaking shall \n",
    "disclose this. In case GHG emissions other than CO2 (particularly N2O) are not \n",
    "available for, or excluded from, location-based grid average emissions factors or \n",
    "with the market-based method information, the undertaking shall disclose this;\n",
    "(f) exclude any purchased, sold or transferred carbon credits or GHG allowances \n",
    "from the calculation of Scope 2 GHG emissions; \n",
    "(g) adhere to the rules as set out in chapter 7.1 of the GHG Protocol Scope 2 \n",
    "Guidance (version 2015 or the latest one) and disclose the required information \n",
    "accordingly; \n",
    "(h) disclose carbon uptakes and emissions (CO2, CO, CH4) from indirect land use \n",
    "and land use change separately from the Scope 2 GHG emissions, but include \n",
    "emissions of other types of GHG when applicable.\n",
    "\"\"\"\n",
    "\n",
    "# template = '''\n",
    "# As an expert in sustainability reports and the new CSRD directive,\n",
    "# your task is to identify relevant paragraph ids from a list of given\n",
    "# paragraphs based on a given regulatory Requirement.\n",
    "# Rank the passages below based on their relevance to the Requirement\n",
    "# and Sub-Requirement in decreasing order. All the passages\n",
    "# should be included and listed using identifiers, in\n",
    "# descending order of relevance. The output format\n",
    "# should be [] > [], e.g., [1] > [2] > [0]. Only respond\n",
    "# with the ranking results, do not say any word or explain.\n",
    "# Requirement: {sample_requirement}\n",
    "# Passages (with their respective passage ID): \n",
    "# {passage_data}\n",
    "# Response:\n",
    "# '''\n",
    "\n",
    "template = '''\n",
    "[INST] <<SYS>>\n",
    "As an expert in sustainability reports and the new CSRD directive,\n",
    "your task is to identify relevant paragraph ids from a list of given\n",
    "paragraphs based on a given regulatory Requirement.\n",
    "Rank the passages below based on their relevance to the Requirement\n",
    "and in decreasing order. All the passages\n",
    "should be included and listed using identifiers, in\n",
    "descending order of relevance. The output format\n",
    "should be [] > [], e.g., [1] > [2] > [0]. Only respond\n",
    "with the ranking results, do not say any word or explain.\n",
    "<</SYS>>\n",
    "Requirement: {sample_requirement}\n",
    "Passages: {passage_data}\n",
    "Response:\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c0f93-5776-469e-bcad-5b4b4a8536e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6cf1c-eeca-4666-bfe2-137c383f4509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[{doc_idx}]: {doc.page_content}\" for doc_idx, doc in enumerate(docs))\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"passage_data\": waliml_retriever | format_docs, \"sample_requirement\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d2092-e19e-462d-8991-7e477db9647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7b7c2-4a01-4444-acc0-48df45d3d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in rag_chain.invoke(sample_requirement):\n",
    "#     print(chunk, end=\"\", flush=True)\n",
    "\n",
    "rag_chain.invoke(\"E1.AR43\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ba88f-d4fb-44ba-b572-24135d260918",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_doc.invoke(\"GHG emissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c11c27-19ab-41b5-8b29-aa83ef0242a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        return [Document(page_content=query)]\n",
    "\n",
    "retriever = CustomRetriever()\n",
    "\n",
    "retriever.get_relevant_documents(\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c17971-c726-4051-9cbf-42d866879c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7459560-7116-4306-a448-7ddbe7dfc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "class WaliMLRetriever(BaseRetriever):\n",
    "    retriever_config: Dict\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str,* , run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        result = []\n",
    "        recommended_doc_dict = self.custom_retriever()\n",
    "        for compliance_item in recommended_doc_dict:\n",
    "            if recommended_doc_dict[compliance_item][\"section_name\"] == query:\n",
    "                recommendations = recommended_doc_dict[compliance_item].get('recommendations', [])\n",
    "                for recommendation in tqdm(recommendations, desc=f\"processing recommendations for {compliance_item}\"):\n",
    "                    blob_data, _ = recommendation\n",
    "                    result.append(Document(page_content=blob_data.pop(\"text\"),\n",
    "                                            metadata=blob_data))\n",
    "\n",
    "        return result\n",
    "    def custom_retriever(self):\n",
    "        if \"debug_doc\" in self.retriever_config:\n",
    "            with open(self.retriever_config['debug_doc']['path'], 'r') as f:\n",
    "                recommended_doc_dict = json.load(f)\n",
    "        else:\n",
    "            pass\n",
    "            # with open(self.retriever_config[\"wali_ml_training_pkldocs\"], 'rb') as f:\n",
    "            #     training_docs = pkl.load(f)\n",
    "            # validation_doc_list = [doc[\"id_\"] for doc in training_docs \n",
    "            #                     if doc['split'].name == \"VALIDATION\"]\n",
    "        return recommended_doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb93b6-5a87-448e-a1d6-54b4431addf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever_config = {\"debug_doc\": {\"path\": \"/cluster/home/srn_recommendation_results/fff9295a-2d30-468c-873c-aa4e6c5d7f14.json\"}}\n",
    "waliml_retriever = WaliMLRetriever(retriever_config=retriever_config)\n",
    "waliml_retriever._get_relevant_documents(\"E1.AR43\",run_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1af45-4de4-42f0-afd0-ce07cb58fd8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[{doc_idx}]: {doc.page_content}\" for doc_idx, doc in enumerate(docs))\n",
    "\n",
    "\n",
    "llama_llm = LlamaCpp(\n",
    "    model_path=\"/cluster/home/repo/my_llm_experiments/llama-weights/13B/llama-2-13b-chat.ggufv3.q8_0.bin\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=512,\n",
    "    n_ctx=5000,\n",
    "    f16_kv=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# llm(\"The first man on the moon was ... Let's think step by step\")\n",
    "\n",
    "\n",
    "local_rag_chain = (\n",
    "    {\"passage_data\": waliml_retriever | format_docs, \"sample_requirement\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llama_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacb154-463c-4c97-a01e-1bf8e4717078",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = local_rag_chain.invoke(\"E1.AR43\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a095053-7c72-4f47-8a7a-c529ee6938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1472f-6269-48aa-8bc8-a30150291d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wali_ml_training_pkldocs = \"/cluster/home/training_runs/esrs_classifier_final/Parsing/ordinary-priority-000/documents.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5502a-6944-448a-baef-6c60a61345cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(wali_ml_training_pkldocs, 'rb') as f:\n",
    "    training_docs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e846b-8286-40cb-81a8-f497f9da50d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_docs[0]['id_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda5423-2fac-4193-8793-8e7c7a3a47d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ced73-4277-40c6-88dc-34fbc17a863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rec_doc = \"/cluster/home/srn_recommendation_results/fff9295a-2d30-468c-873c-aa4e6c5d7f14.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf6d87-b3b5-4a33-959f-9d76540e863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_rec_doc, 'r') as f:\n",
    "    rec_doc_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be49ef-8fc4-4740-9eaf-cfe3bbf2098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_doc_dict['gross scope 2 GHG emissions (market-based), change to prior fy in %'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b82ebe-5ef8-4ed5-84ef-a697639a6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_doc_dict['gross scope 2 GHG emissions (market-based), change to prior fy in %']['section_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901a57f-3910-4f20-8ac7-c5706f93d318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425a593-b08c-42c9-b1cd-1e803ebfcefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a4ab6-dee4-41d5-a639-4ecb15cc56ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
