{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a863db72-761f-47ca-9899-644d87587b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from srn_data_collector.parse_esrs_requirements.parse_esrs_for_rag import parse_data\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e188335-82a9-4f63-b68c-d06f585e83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pth = open('/root/.config/openai.txt')\n",
    "ls_file = open('/root/.config/langsmith.txt')\n",
    "os.environ[\"OPENAI_API_KEY\"] = file_pth.read().strip()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = ls_file.read().strip()\n",
    "\n",
    "#cuBLAS settings for llama inference\n",
    "os.environ[\"CMAKE_ARGS\"] = \"-DLLAMA_BLAS=on -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
    "os.environ[\"FORCE_CMAKE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2725ae-5bff-4bb9-ab70-7a39b3570faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "esrs_parsed_json = '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/esrs_requirement_main.json'\n",
    "esrs_sample_json = '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/query_req_data.json'\n",
    "recommendation_response_path = '/cluster/home/srn_storage/sample_retriever_recommendations'\n",
    "sample_pdf_raw_parsed_json_path = '/cluster/home/srn_storage/7aa3d012-661d-4953-8516-30c3cf87fb33/2022/AR/fff9295a-2d30-468c-873c-aa4e6c5d7f14.json'\n",
    "sample_pdf_formatted_path = '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f73efc-34d2-4c76-83b1-c139014c2803",
   "metadata": {},
   "source": [
    "### Loading requirements into vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7effc120-0037-4bc1-82d1-102d863c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esrs_parsed = parse_data(esrs_parsed_json)\n",
    "# with open(esrs_sample_json, 'w') as f:\n",
    "#     json.dump(esrs_parsed,f)\n",
    "\n",
    "# esrs_parsed\n",
    "\n",
    "# esrs_parsed.keys()\n",
    "\n",
    "# main_categories_map = {\"environmental\": ['climate change', 'pollution', 'water and marine resources', 'biodiversity and ecosystems'],\n",
    "#                       \"social\": ['circular economy', 'own workforce', 'workers in the value chain', 'affected communities', 'consumers and end-users'],\n",
    "#                       \"global\" : [\"business conduct\"]}\n",
    "\n",
    "# def q_builder_metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "#     metadata[\"label\"] = record.get(\"label\")\n",
    "\n",
    "#     return metadata\n",
    "\n",
    "# loader = JSONLoader(\n",
    "#     file_path=esrs_sample_json,\n",
    "#     jq_schema=' .\"climate change\"[], .\"own workforce\"[], .\"business conduct\"[]',\n",
    "#     text_content=False,\n",
    "#     content_key='text',\n",
    "#     metadata_func=q_builder_metadata_func)\n",
    "\n",
    "# query_data = loader.load()\n",
    "\n",
    "# len(query_data)\n",
    "\n",
    "# query_data[0].page_content\n",
    "\n",
    "# query_data[0].metadata\n",
    "\n",
    "# # text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# # splits_query = text_splitter.split_documents(query_data)\n",
    "# # vectorstore_query = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "# vectorstore_query = Chroma.from_documents(documents=query_data, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# # Retrieve and generate using the relevant snippets of the blog.\n",
    "# query_retriever = vectorstore_query.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# query_retriever.invoke(\"Query about Climate change, GHG emissions\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c71618-a2f1-4806-9bea-70def438861c",
   "metadata": {},
   "source": [
    "### Loading entire document in vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c8f2f1-be06-441b-bbdc-13ee1d0871d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_pdf_raw_parsed_json_path, 'r') as f:\n",
    "    sample_doc_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49affb87-87e7-4262-bc02-18fdc538e44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_formatted_data = {\"doc_data\" : []}\n",
    "for doc_ref, blob_list in sample_doc_dict.items():\n",
    "    for blob_id, blob_data in enumerate(blob_list):\n",
    "        doc_formatted_data['doc_data'].append({\"text\": blob_data['text'], \"blob_id\": blob_id, \"doc_ref\": doc_ref})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ac6e1c7-9722-4533-8178-194607c0a65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(sample_pdf_formatted_path, 'w') as f:\n",
    "    json.dump(doc_formatted_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ffe98b9-6dce-433e-8eb6-2f220958a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    metadata[\"blob_id\"] = record.get(\"blob_id\")\n",
    "    metadata[\"doc_ref\"] = record.get(\"doc_ref\")\n",
    "\n",
    "    # if \"source\" in metadata:\n",
    "    #     source = metadata[\"source\"].split(\"/\")\n",
    "    #     source = source[source.index(\"langchain\"):]\n",
    "    #     metadata[\"source\"] = \"/\".join(source)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efce9194-068e-4f1b-aeac-b72c29845e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JSONLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doc_loader \u001b[38;5;241m=\u001b[39m \u001b[43mJSONLoader\u001b[49m(\n\u001b[1;32m      2\u001b[0m     file_path\u001b[38;5;241m=\u001b[39msample_pdf_formatted_path,\n\u001b[1;32m      3\u001b[0m     jq_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.doc_data[]\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     text_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     content_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     metadata_func\u001b[38;5;241m=\u001b[39mmetadata_func)\n\u001b[1;32m      8\u001b[0m doc_data \u001b[38;5;241m=\u001b[39m doc_loader\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'JSONLoader' is not defined"
     ]
    }
   ],
   "source": [
    "doc_loader = JSONLoader(\n",
    "    file_path=sample_pdf_formatted_path,\n",
    "    jq_schema='.doc_data[]',\n",
    "    text_content=False,\n",
    "    content_key='text',\n",
    "    metadata_func=metadata_func)\n",
    "\n",
    "doc_data = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e49dd51-9644-4bdf-b302-f8f748739ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits_doc = text_splitter.split_documents(doc_data)\n",
    "# vectorstore_doc = Chroma.from_documents(documents=splits_doc, embedding=OpenAIEmbeddings())\n",
    "vectorstore_doc = Chroma.from_documents(documents=doc_data, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever_doc = vectorstore_doc.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffc3b0e7-4f95-4f99-baf6-2b55bcec882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Connect. \\nGrow.\\nThrive.\\n2022 Annual Report', metadata={'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json', 'seq_num': 1, 'blob_id': 0, 'doc_ref': '1'})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a2fb09-be2b-408f-9ae3-cef48ca0de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt template \n",
    "sample_requirement = \"\"\"\n",
    "AR 43. When preparing the information on gross Scope 2 GHG emissions required under \n",
    "paragraph 46, the undertaking shall:\n",
    "(a) consider the principles and requirements of the GHG Protocol Scope 2 Guidance \n",
    "(version 2015 or the latest one); it may also consider corresponding requirements \n",
    "for the quantification of indirect GHG emissions from imported energy in ISO \n",
    "14064-1:2018;\n",
    "(b) include purchased or acquired electricity, steam, heat, and cooling consumed by \n",
    "the undertaking; \n",
    "(c) avoid double counting of GHG emissions reported under Scope 1 or 3;\n",
    "(d) apply the location-based and market-based methods to calculate Scope 2 GHG \n",
    "emissions;\n",
    "Note: Location-based method quantifies Scope 2 GHG emissions based on \n",
    "average energy generation emission factors for defined locations, including local, \n",
    "subnational, or national boundaries (GHG Protocol, �Scope 2 Guidance�, \n",
    "Glossary, 2015);\n",
    "Note: Market-based method quantifies Scope 2 GHG emissions based on GHG \n",
    "emissions emitted by the generators from which the reporting entity contractually \n",
    "purchases electricity bundled with instruments, or unbundled instruments on their \n",
    "own (GHG Protocol, �Scope 2 Guidance�, Glossary, 2015); in this case, the \n",
    "undertaking may disclose the share of market-based scope 2 GHG emissions \n",
    "linked to purchased electricity bundled with instruments such as Guarantee of \n",
    "Origins or Renewable Energy Certificates.\n",
    "(e) disclose biogenic emissions of carbon from the combustion or biodegradation of \n",
    "biomass separately from the Scope 2 GHG emissions but include emissions of \n",
    "other types of GHG (in particular N2O). In case the emission factors applied do \n",
    "not separate the percentage of biomass or biogenic CO2, the undertaking shall \n",
    "disclose this. In case GHG emissions other than CO2 (particularly N2O) are not \n",
    "available for, or excluded from, location-based grid average emissions factors or \n",
    "with the market-based method information, the undertaking shall disclose this;\n",
    "(f) exclude any purchased, sold or transferred carbon credits or GHG allowances \n",
    "from the calculation of Scope 2 GHG emissions; \n",
    "(g) adhere to the rules as set out in chapter 7.1 of the GHG Protocol Scope 2 \n",
    "Guidance (version 2015 or the latest one) and disclose the required information \n",
    "accordingly; \n",
    "(h) disclose carbon uptakes and emissions (CO2, CO, CH4) from indirect land use \n",
    "and land use change separately from the Scope 2 GHG emissions, but include \n",
    "emissions of other types of GHG when applicable.\n",
    "\"\"\"\n",
    "\n",
    "# template = '''\n",
    "# As an expert in sustainability reports and the new CSRD directive,\n",
    "# your task is to identify relevant paragraph ids from a list of given\n",
    "# paragraphs based on a given regulatory Requirement.\n",
    "# Rank the passages below based on their relevance to the Requirement\n",
    "# and Sub-Requirement in decreasing order. All the passages\n",
    "# should be included and listed using identifiers, in\n",
    "# descending order of relevance. The output format\n",
    "# should be [] > [], e.g., [1] > [2] > [0]. Only respond\n",
    "# with the ranking results, do not say any word or explain.\n",
    "# Requirement: {sample_requirement}\n",
    "# Passages (with their respective passage ID): \n",
    "# {passage_data}\n",
    "# Response:\n",
    "# '''\n",
    "\n",
    "template = '''\n",
    "[INST] <<SYS>>\n",
    "As an expert in sustainability reports and the new CSRD directive,\n",
    "your task is to identify relevant paragraph ids from a list of given\n",
    "paragraphs based on a given regulatory Requirement.\n",
    "Rank the passages below based on their relevance to the Requirement\n",
    "and in decreasing order. All the passages\n",
    "should be included and listed using identifiers, in\n",
    "descending order of relevance. The output format\n",
    "should be [] > [], e.g., [1] > [2] > [0]. Only respond\n",
    "with the ranking results, do not say any word or explain.\n",
    "<</SYS>>\n",
    "Requirement: {sample_requirement}\n",
    "Passages: {passage_data}\n",
    "Response:\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64c0f93-5776-469e-bcad-5b4b4a8536e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdf6cf1c-eeca-4666-bfe2-137c383f4509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[{doc_idx}]: {doc.page_content}\" for doc_idx, doc in enumerate(docs))\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"passage_data\": waliml_retriever | format_docs, \"sample_requirement\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d3d2092-e19e-462d-8991-7e477db9647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb7b7c2-4a01-4444-acc0-48df45d3d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing recommendations for gross scope 2 GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 9822.\n",
      "processing recommendations for total gross GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 10613.1\n",
      "processing recommendations for total gross scope 3 GHG emissions, fy/fy-1 in %: 100%|██████████████| 5/5 [00:00<00:00, 9901.57it/s]\n",
      "processing recommendations for gross scope 1 GHG emissions, change to prior fy in %: 100%|████████| 5/5 [00:00<00:00, 17697.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[3] > [9] > [4] > [11] > [1] > [6] > [13] > [14] > [16] > [17] > [18] > [19] > [0] > [2] > [5] > [7] > [8] > [10] > [12] > [15]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for chunk in rag_chain.invoke(sample_requirement):\n",
    "#     print(chunk, end=\"\", flush=True)\n",
    "\n",
    "rag_chain.invoke(\"E1.AR43\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86ba88f-d4fb-44ba-b572-24135d260918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='GHG Emissions:', metadata={'blob_id': 4, 'doc_ref': '36', 'seq_num': 270, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'}),\n",
       " Document(page_content='Science-Based GHG Target', metadata={'blob_id': 5, 'doc_ref': '35', 'seq_num': 259, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'}),\n",
       " Document(page_content='Scope 1 emissions include fugitive emissions using emission factors from the “Refrigerant & other” worksheet in the condensed set of the 2021 UK GHG Conversion factors set. \\nEmissions from fuel (motor diesel and gasoline) are calculated using the World Resources Institute (2015) GHG Protocol Tool for Stationary Combustion (version 4.1) and the \\nMobile Combustion GHG Emissions Calculation Tool (version 2.6).\\nScope 2 emissions (market-based method) were calculated using Electricity Emission Factors from IEA, except in the case of Colombia (as from 2021).\\nScope 3 emissions computation was performed with reference to the GHG Protocol methodology, and was calculated by an expert third party, whenever feasible and \\nrelevant. Scope 3 categories 10 (Processing of sold products), 13 (Downstream leased assets) and 14 (Franchises) were not included because they are not applicable to', metadata={'blob_id': 9, 'doc_ref': '65', 'seq_num': 507, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'}),\n",
       " Document(page_content='ESG Governance', metadata={'blob_id': 6, 'doc_ref': '31', 'seq_num': 227, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'}),\n",
       " Document(page_content='ESG Approach', metadata={'blob_id': 1, 'doc_ref': '31', 'seq_num': 222, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'}),\n",
       " Document(page_content='Validated by the Science-Based Target initiative, our new GHG emissions \\nreduction targets provide a clearly defined pathway for reducing our impac', metadata={'blob_id': 2, 'doc_ref': '34', 'seq_num': 248, 'source': '/cluster/home/repo/my_llm_experiments/esrs_data_collection/srn_data_collector/parse_esrs_requirements/docu_data.json'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_doc.invoke(\"GHG emissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c11c27-19ab-41b5-8b29-aa83ef0242a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='bar')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        return [Document(page_content=query)]\n",
    "\n",
    "retriever = CustomRetriever()\n",
    "\n",
    "retriever.get_relevant_documents(\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c17971-c726-4051-9cbf-42d866879c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7459560-7116-4306-a448-7ddbe7dfc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "class WaliMLRetriever(BaseRetriever):\n",
    "    retriever_config: Dict\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str,* , run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        result = []\n",
    "        recommended_doc_dict = self.custom_retriever()\n",
    "        for compliance_item in recommended_doc_dict:\n",
    "            if recommended_doc_dict[compliance_item][\"section_name\"] == query:\n",
    "                recommendations = recommended_doc_dict[compliance_item].get('recommendations', [])\n",
    "                for recommendation in tqdm(recommendations, desc=f\"processing recommendations for {compliance_item}\"):\n",
    "                    blob_data, _ = recommendation\n",
    "                    result.append(Document(page_content=blob_data.pop(\"text\"),\n",
    "                                            metadata=blob_data))\n",
    "\n",
    "        return result\n",
    "    def custom_retriever(self):\n",
    "        if \"debug_doc\" in self.retriever_config:\n",
    "            with open(self.retriever_config['debug_doc']['path'], 'r') as f:\n",
    "                recommended_doc_dict = json.load(f)\n",
    "        else:\n",
    "            pass\n",
    "            # with open(self.retriever_config[\"wali_ml_training_pkldocs\"], 'rb') as f:\n",
    "            #     training_docs = pkl.load(f)\n",
    "            # validation_doc_list = [doc[\"id_\"] for doc in training_docs \n",
    "            #                     if doc['split'].name == \"VALIDATION\"]\n",
    "        return recommended_doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fb93b6-5a87-448e-a1d6-54b4431addf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing recommendations for gross scope 2 GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 8694.\n",
      "processing recommendations for total gross GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 17985.8\n",
      "processing recommendations for total gross scope 3 GHG emissions, fy/fy-1 in %: 100%|█████████████| 5/5 [00:00<00:00, 12858.07it/s]\n",
      "processing recommendations for gross scope 1 GHG emissions, change to prior fy in %: 100%|████████| 5/5 [00:00<00:00, 19544.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Energy use\\nKPI\\n2020\\n2021\\n2022\\nBase station and fixed network sites\\nEnergy from fuel (MWh)\\n \\n46,721  \\n46,590  \\n50,046 \\nGrid electricity (MWh)\\n \\n459,496  \\n514,684  \\n532,301 \\nOur fleet\\nEnergy from fuel (MWh)\\n \\n53,630  \\n52,017  \\n45,803 \\nData centers and offices\\nEnergy from fuel (MWh)\\n \\n3,220  \\n2,281  \\n2,350 \\nGrid electricity (MWh)\\n \\n124,808  \\n118,679  \\n131,975 \\nShops\\nEnergy from fuel (MWh)\\n \\n626  \\n105  \\n109 \\nGrid electricity (MWh)\\n \\n16,538  \\n13,304  \\n14,401 \\nTotal energy consumption (MWh)\\nGrid electricity (MWh)\\n \\n600,842  \\n646,667  \\n678,677 \\nEnergy from fuel (MWh)\\n \\n104,197  \\n100,993  \\n98,308 \\nTotal energy consumption (MWh)\\n \\n705,039  \\n747,660  \\n776,985 \\nOut of which energy from renewable sources (MWh)\\nNew KPI for 2021  \\n18,772  \\n28,208 \\nScope 1 emissions (Tonnes of CO2e)\\n \\n33,629  \\n33,161  \\n31,942 \\nScope 2 emissions (Tonnes of CO2e)\\n \\n152,060  \\n146,525  \\n139,242 \\nScope 3 emissions (Tonnes of CO2e)\\n \\n1,585,057  \\n2,202,250  \\n1,582,304', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9998722076416016, 'box': [0.09233692288398743, 0.8958215117454529, 0.47780683636665344, 0.8000819087028503], 'blob_id': 8, 'document_ref': '65', 'page_number': '65'}),\n",
       " Document(page_content='Renewable Energy vs. \\nTotal Energy Consumption\\n— Energy from renewable sources (MWh)\\n— Total energy consumption (MWh)', metadata={'class_id': 2, 'class_name': 'headline', 'confidence': 0.9820201992988586, 'box': [0.5107141733169556, 0.7963626980781555, 0.3146282434463501, 0.3866707384586334], 'blob_id': 5, 'document_ref': '37', 'page_number': '37'}),\n",
       " Document(page_content='46%', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.847581148147583, 'box': [0.038073692470788956, 0.7665525674819946, 0.6250023245811462, 0.8856415152549744], 'blob_id': 8, 'document_ref': '54', 'page_number': '54'}),\n",
       " Document(page_content='Tigo Colombia certified 24,382 MWh of its grid electricity \\nconsumption in 2022 through RECs, verifying that the energy \\nwas generated from renewable sources and fed into the \\nnational grid.  \\nAs a side benefit, our procurement of renewable energy may \\nhelp the countries in which we operate meet their own climate\\ncommitments, such as Colombia’s pledge to reduce GHG \\nemissions by 51% by 2030. Our actions to reduce demand on\\nthe grid, drive demand for renewable energy sources and \\ncreate new mechanisms for renewable energy procurement \\ncan all play a role in changing this energy equation.', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9960099458694458, 'box': [0.47513774037361145, 0.8912215232849121, 0.14065840102607952, 0.30556604266166687], 'blob_id': 4, 'document_ref': '37', 'page_number': '37'}),\n",
       " Document(page_content='A relentless focus on energy efficiency and renewable energy sourcing are at\\nthe core of our net-zero strategy.', metadata={'class_id': 2, 'class_name': 'headline', 'confidence': 0.9988898634910583, 'box': [0.07866409420967102, 0.8905683192261185, 0.12646973133087158, 0.16983120143413544], 'blob_id': 2, 'document_ref': '36', 'page_number': '36'}),\n",
       " Document(page_content='Energy use\\nKPI\\n2020\\n2021\\n2022\\nBase station and fixed network sites\\nEnergy from fuel (MWh)\\n \\n46,721  \\n46,590  \\n50,046 \\nGrid electricity (MWh)\\n \\n459,496  \\n514,684  \\n532,301 \\nOur fleet\\nEnergy from fuel (MWh)\\n \\n53,630  \\n52,017  \\n45,803 \\nData centers and offices\\nEnergy from fuel (MWh)\\n \\n3,220  \\n2,281  \\n2,350 \\nGrid electricity (MWh)\\n \\n124,808  \\n118,679  \\n131,975 \\nShops\\nEnergy from fuel (MWh)\\n \\n626  \\n105  \\n109 \\nGrid electricity (MWh)\\n \\n16,538  \\n13,304  \\n14,401 \\nTotal energy consumption (MWh)\\nGrid electricity (MWh)\\n \\n600,842  \\n646,667  \\n678,677 \\nEnergy from fuel (MWh)\\n \\n104,197  \\n100,993  \\n98,308 \\nTotal energy consumption (MWh)\\n \\n705,039  \\n747,660  \\n776,985 \\nOut of which energy from renewable sources (MWh)\\nNew KPI for 2021  \\n18,772  \\n28,208 \\nScope 1 emissions (Tonnes of CO2e)\\n \\n33,629  \\n33,161  \\n31,942 \\nScope 2 emissions (Tonnes of CO2e)\\n \\n152,060  \\n146,525  \\n139,242 \\nScope 3 emissions (Tonnes of CO2e)\\n \\n1,585,057  \\n2,202,250  \\n1,582,304', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9998722076416016, 'box': [0.09233692288398743, 0.8958215117454529, 0.47780683636665344, 0.8000819087028503], 'blob_id': 8, 'document_ref': '65', 'page_number': '65'}),\n",
       " Document(page_content='Renewable Energy vs. \\nTotal Energy Consumption\\n— Energy from renewable sources (MWh)\\n— Total energy consumption (MWh)', metadata={'class_id': 2, 'class_name': 'headline', 'confidence': 0.9820201992988586, 'box': [0.5107141733169556, 0.7963626980781555, 0.3146282434463501, 0.3866707384586334], 'blob_id': 5, 'document_ref': '37', 'page_number': '37'}),\n",
       " Document(page_content='urther, the committee increased its emphasis on the processes leading to ESG disclosures, \\nerformance metrics, targets and the EU Taxonomy, including the design and testing of controls to\\nrify the accuracy of these reports.', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9958261251449585, 'box': [0.31113389134407043, 0.8894007205963135, 0.49733448028564453, 0.538626492023468], 'blob_id': 2, 'document_ref': '88', 'page_number': '88'}),\n",
       " Document(page_content='46%', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.847581148147583, 'box': [0.038073692470788956, 0.7665525674819946, 0.6250023245811462, 0.8856415152549744], 'blob_id': 8, 'document_ref': '54', 'page_number': '54'}),\n",
       " Document(page_content='This process, which we term reverse logistics, helped us avoid \\nthe purchase of more than $126 million in new CPE in 2022. It\\nalso lessens the impact of microchip shortages or other supply\\nchain disruptions to our business.', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9998685121536255, 'box': [0.09433145821094513, 0.47497299313545227, 0.27470463514328003, 0.3300655782222748], 'blob_id': 4, 'document_ref': '39', 'page_number': '39'}),\n",
       " Document(page_content='Energy use\\nKPI\\n2020\\n2021\\n2022\\nBase station and fixed network sites\\nEnergy from fuel (MWh)\\n \\n46,721  \\n46,590  \\n50,046 \\nGrid electricity (MWh)\\n \\n459,496  \\n514,684  \\n532,301 \\nOur fleet\\nEnergy from fuel (MWh)\\n \\n53,630  \\n52,017  \\n45,803 \\nData centers and offices\\nEnergy from fuel (MWh)\\n \\n3,220  \\n2,281  \\n2,350 \\nGrid electricity (MWh)\\n \\n124,808  \\n118,679  \\n131,975 \\nShops\\nEnergy from fuel (MWh)\\n \\n626  \\n105  \\n109 \\nGrid electricity (MWh)\\n \\n16,538  \\n13,304  \\n14,401 \\nTotal energy consumption (MWh)\\nGrid electricity (MWh)\\n \\n600,842  \\n646,667  \\n678,677 \\nEnergy from fuel (MWh)\\n \\n104,197  \\n100,993  \\n98,308 \\nTotal energy consumption (MWh)\\n \\n705,039  \\n747,660  \\n776,985 \\nOut of which energy from renewable sources (MWh)\\nNew KPI for 2021  \\n18,772  \\n28,208 \\nScope 1 emissions (Tonnes of CO2e)\\n \\n33,629  \\n33,161  \\n31,942 \\nScope 2 emissions (Tonnes of CO2e)\\n \\n152,060  \\n146,525  \\n139,242 \\nScope 3 emissions (Tonnes of CO2e)\\n \\n1,585,057  \\n2,202,250  \\n1,582,304', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9998722076416016, 'box': [0.09233692288398743, 0.8958215117454529, 0.47780683636665344, 0.8000819087028503], 'blob_id': 8, 'document_ref': '65', 'page_number': '65'}),\n",
       " Document(page_content='Scope 3 (tonnes of CO2e', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9950961470603943, 'box': [0.6725968718528748, 0.833292543888092, 0.273325651884079, 0.28894227743148804], 'blob_id': 6, 'document_ref': '36', 'page_number': '36'}),\n",
       " Document(page_content='illicom uses the following fair value measurement hierarchy:', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.8934618830680847, 'box': [0.08510266989469528, 0.517927348613739, 0.8805412650108337, 0.8973621129989624], 'blob_id': 17, 'document_ref': '194', 'page_number': '194'}),\n",
       " Document(page_content='M i l l i c o m  2 0 2 2  A n n u a l  R e p o r t    5 3\\nOur ESG Approach and Impact', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9972625970840454, 'box': [0.28954431414604187, 1.0, 0.0017156976973637938, 0.437783807516098], 'blob_id': 0, 'document_ref': '55', 'page_number': '55'}),\n",
       " Document(page_content='(ii) In June 2021, Millicom disposed of its entire stake in HT for a total net consideration of $163 million, triggering a net loss on disposal of $15 million \\nrecorded in the statement of income under ‘other operating income (expenses), net’. The changes in fair value prior to the disposal were shown under \"Other \\nnon-operating (expenses) income, net\"', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9948325157165527, 'box': [0.07800262421369553, 0.9203425049781799, 0.4013156294822693, 0.4445289969444275], 'blob_id': 6, 'document_ref': '173', 'page_number': '173'}),\n",
       " Document(page_content='Energy use\\nKPI\\n2020\\n2021\\n2022\\nBase station and fixed network sites\\nEnergy from fuel (MWh)\\n \\n46,721  \\n46,590  \\n50,046 \\nGrid electricity (MWh)\\n \\n459,496  \\n514,684  \\n532,301 \\nOur fleet\\nEnergy from fuel (MWh)\\n \\n53,630  \\n52,017  \\n45,803 \\nData centers and offices\\nEnergy from fuel (MWh)\\n \\n3,220  \\n2,281  \\n2,350 \\nGrid electricity (MWh)\\n \\n124,808  \\n118,679  \\n131,975 \\nShops\\nEnergy from fuel (MWh)\\n \\n626  \\n105  \\n109 \\nGrid electricity (MWh)\\n \\n16,538  \\n13,304  \\n14,401 \\nTotal energy consumption (MWh)\\nGrid electricity (MWh)\\n \\n600,842  \\n646,667  \\n678,677 \\nEnergy from fuel (MWh)\\n \\n104,197  \\n100,993  \\n98,308 \\nTotal energy consumption (MWh)\\n \\n705,039  \\n747,660  \\n776,985 \\nOut of which energy from renewable sources (MWh)\\nNew KPI for 2021  \\n18,772  \\n28,208 \\nScope 1 emissions (Tonnes of CO2e)\\n \\n33,629  \\n33,161  \\n31,942 \\nScope 2 emissions (Tonnes of CO2e)\\n \\n152,060  \\n146,525  \\n139,242 \\nScope 3 emissions (Tonnes of CO2e)\\n \\n1,585,057  \\n2,202,250  \\n1,582,304', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9998722076416016, 'box': [0.09233692288398743, 0.8958215117454529, 0.47780683636665344, 0.8000819087028503], 'blob_id': 8, 'document_ref': '65', 'page_number': '65'}),\n",
       " Document(page_content='2022 plans\\n2021 plans\\n2020 plans\\n2019 plans\\nPSP\\nDSP\\nPSP\\nDSP\\nPSP\\nDSP\\nPSP\\nDSP\\n(number of shares)\\nInitial shares granted\\n306,641 \\n865,862 \\n451,363 \\n536,890 \\n341,897 \\n370,131 \\n257,601 \\n297,856 \\nAdditional shares granted(i)\\n— \\n47,588 \\n— \\n5,824 \\n— \\n5,928 \\n— \\n43,115 \\nEffect of the Right Offering(ii)\\n83,926 \\n227,947 \\n115,575 \\n93,375 \\n20,862 \\n32,526 \\n— \\n— \\nRevision for forfeitures\\n— \\n(21,990) \\n(25,938) \\n(28,130) \\n(265,632) \\n(34,857) \\n(257,293) \\n(32,253) \\nRevision for cancellations\\n— \\n— \\n— \\n(9,250) \\n— \\n(4,996) \\n— \\n— \\nTotal before issuances\\n390,567  1,119,407 \\n541,000 \\n598,709 \\n97,127 \\n368,732 \\n308 \\n308,718 \\nShares issued in 2019\\n— \\n— \\n— \\n— \\n— \\n— \\n(150) \\n(24,294)\\nShares issued in 2020\\n— \\n— \\n— \\n— \\n— \\n(3,571) \\n(17) \\n(96,629)\\nShares issued in 2021\\n— \\n— \\n(1,121) \\n(5,760) \\n— \\n(113,653) \\n—  \\n(87,141)\\nShares issued in 2022\\n— \\n(13,957) \\n(2,071) \\n(160,596) \\n— \\n(100,362) \\n(141) \\n(100,654)\\nPerformance conditions not met\\n— \\n— \\n— \\n— \\n(97,127) \\n— \\n— \\n— \\nShares still expected to vest\\n390,567  1,105,450 \\n537,808 \\n432,353 \\n— \\n151,146 \\n— \\n— \\nEstimated cost over the vesting period (US$ \\nmillions)\\n7 \\n20 \\n16 \\n19 \\n4 \\n15 \\nna\\nna', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.9999990463256836, 'box': [0.08129486441612244, 0.9248660206794739, 0.3400445282459259, 0.6003059148788452], 'blob_id': 5, 'document_ref': '169', 'page_number': '169'}),\n",
       " Document(page_content='46%', metadata={'class_id': 5, 'class_name': 'table', 'confidence': 0.847581148147583, 'box': [0.038073692470788956, 0.7665525674819946, 0.6250023245811462, 0.8856415152549744], 'blob_id': 8, 'document_ref': '54', 'page_number': '54'}),\n",
       " Document(page_content='Risk Management Approach', metadata={'class_id': 2, 'class_name': 'headline', 'confidence': 0.9997798800468445, 'box': [0.10504807531833649, 0.3583817183971405, 0.0832841768860817, 0.10194750875234604], 'blob_id': 1, 'document_ref': '26', 'page_number': '26'}),\n",
       " Document(page_content='(ii) In June 2021, Millicom disposed of its entire stake in HT for a total net consideration of $163 million, triggering a net loss on disposal of $15 million \\nrecorded in the statement of income under ‘other operating income (expenses), net’. The changes in fair value prior to the disposal were shown under \"Other \\nnon-operating (expenses) income, net\"', metadata={'class_id': 4, 'class_name': 'paragraph', 'confidence': 0.9948325157165527, 'box': [0.07800262421369553, 0.9203425049781799, 0.4013156294822693, 0.4445289969444275], 'blob_id': 6, 'document_ref': '173', 'page_number': '173'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_config = {\"debug_doc\": {\"path\": \"/cluster/home/srn_recommendation_results/fff9295a-2d30-468c-873c-aa4e6c5d7f14.json\"}}\n",
    "waliml_retriever = WaliMLRetriever(retriever_config=retriever_config)\n",
    "waliml_retriever._get_relevant_documents(\"E1.AR43\",run_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e1af45-4de4-42f0-afd0-ce07cb58fd8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 8 CUDA devices:\n",
      "  Device 0: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 1: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 2: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 3: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 4: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 5: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 6: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "  Device 7: Tesla V100-SXM2-32GB, compute capability 7.0, VMM: yes\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /cluster/home/repo/my_llm_experiments/llama-weights/13B/llama-2-13b-chat.ggufv3.q8_0.bin (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = llama-2-13b-chat.ggmlv3.q8_0.bin\n",
      "llama_model_loader: - kv   2:                        general.description str              = converted from legacy GGJTv3 MOSTLY_Q...\n",
      "llama_model_loader: - kv   3:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv   4:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   5:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   8:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000005\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q8_0:  282 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 5.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 12.88 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = llama-2-13b-chat.ggmlv3.q8_0.bin\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    1.25 MiB\n",
      "llm_load_tensors: offloading 40 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 41/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   166.02 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  1928.67 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA2 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA3 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA4 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA5 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA6 buffer size =  1607.23 MiB\n",
      "llm_load_tensors:      CUDA7 buffer size =  1451.82 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 5000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   585.94 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA2 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA3 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA4 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA5 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA6 KV buffer size =   488.28 MiB\n",
      "llama_kv_cache_init:      CUDA7 KV buffer size =   390.62 MiB\n",
      "llama_new_context_with_model: KV self size  = 3906.25 MiB, K (f16): 1953.12 MiB, V (f16): 1953.12 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    19.79 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA2 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA3 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA4 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA5 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA6 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:      CUDA7 compute buffer size =   473.43 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    11.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 17\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Model metadata: {'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'general.architecture': 'llama', 'llama.context_length': '2048', 'general.name': 'llama-2-13b-chat.ggmlv3.q8_0.bin', 'general.description': 'converted from legacy GGJTv3 MOSTLY_Q8_0 format', 'llama.embedding_length': '5120', 'general.file_type': '7', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000005', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '40', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'tokenizer.ggml.model': 'llama'}\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[{doc_idx}]: {doc.page_content}\" for doc_idx, doc in enumerate(docs))\n",
    "\n",
    "\n",
    "llama_llm = LlamaCpp(\n",
    "    model_path=\"/cluster/home/repo/my_llm_experiments/llama-weights/13B/llama-2-13b-chat.ggufv3.q8_0.bin\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=512,\n",
    "    n_ctx=5000,\n",
    "    f16_kv=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# llm(\"The first man on the moon was ... Let's think step by step\")\n",
    "\n",
    "\n",
    "local_rag_chain = (\n",
    "    {\"passage_data\": waliml_retriever | format_docs, \"sample_requirement\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llama_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aacb154-463c-4c97-a01e-1bf8e4717078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing recommendations for gross scope 2 GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 14810\n",
      "processing recommendations for total gross GHG emissions (market-based), change to prior fy in %: 100%|█| 5/5 [00:00<00:00, 19099.7\n",
      "processing recommendations for total gross scope 3 GHG emissions, fy/fy-1 in %: 100%|█████████████| 5/5 [00:00<00:00, 11143.21it/s]\n",
      "processing recommendations for gross scope 1 GHG emissions, change to prior fy in %: 100%|████████| 5/5 [00:00<00:00, 20500.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " on the provided passages, I have ranked them based on their relevance to E1.AR43 as follows:\n",
      "\n",
      "[1] > [2] > [3] > [4] > [5] > [6] > [7] > [8] > [9] > [10] > [11] > [12] > [13] > [14] > [15] > [16] > [17] > [18] > [19]\n",
      "\n",
      "The most relevant passages are:\n",
      "\n",
      "[1] > [2] > [3] > [4] > [5] > [6] > [7] > [8] > [9] > [10] > [11] > [12] > [13] > [14] > [15] > [16] > [17] > [18] > [19]\n",
      "\n",
      "Note: The ranking is based on the relevance to E1.AR43, not necessarily on the importance or popularity of the passage."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     334.26 ms\n",
      "llama_print_timings:      sample time =     119.95 ms /   243 runs   (    0.49 ms per token,  2025.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    8519.28 ms /   243 runs   (   35.06 ms per token,    28.52 tokens per second)\n",
      "llama_print_timings:       total time =    9595.29 ms /   244 tokens\n"
     ]
    }
   ],
   "source": [
    "x = local_rag_chain.invoke(\"E1.AR43\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a095053-7c72-4f47-8a7a-c529ee6938e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided passages, I have ranked them based on their relevance to E1.AR43 as follows:\\n\\n[1] > [2] > [3] > [4] > [5] > [6] > [7] > [8] > [9] > [10] > [11] > [12] > [13] > [14] > [15] > [16] > [17] > [18] > [19]\\n\\nThe most relevant passages are:\\n\\n[1] > [2] > [3] > [4] > [5] > [6] > [7] > [8] > [9] > [10] > [11] > [12] > [13] > [14] > [15] > [16] > [17] > [18] > [19]\\n\\nNote: The ranking is based on the relevance to E1.AR43, not necessarily on the importance or popularity of the passage.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6c1472f-6269-48aa-8bc8-a30150291d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wali_ml_training_pkldocs = \"/cluster/home/training_runs/esrs_classifier_final/Parsing/ordinary-priority-000/documents.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffa5502a-6944-448a-baef-6c60a61345cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/lit-llama/lib/python3.11/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_inputs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(wali_ml_training_pkldocs, 'rb') as f:\n",
    "    training_docs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e92e846b-8286-40cb-81a8-f497f9da50d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95df1d10-26ac-4bc2-a4b5-41f1698cac24'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_docs[0]['id_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda5423-2fac-4193-8793-8e7c7a3a47d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "058ced73-4277-40c6-88dc-34fbc17a863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rec_doc = \"/cluster/home/srn_recommendation_results/fff9295a-2d30-468c-873c-aa4e6c5d7f14.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5cf6d87-b3b5-4a33-959f-9d76540e863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_rec_doc, 'r') as f:\n",
    "    rec_doc_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67be49ef-8fc4-4740-9eaf-cfe3bbf2098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['recommendations', 'ground_truth', 'section_name', 'section_name_text'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_doc_dict['gross scope 2 GHG emissions (market-based), change to prior fy in %'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75b82ebe-5ef8-4ed5-84ef-a697639a6c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E1.AR43'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_doc_dict['gross scope 2 GHG emissions (market-based), change to prior fy in %']['section_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901a57f-3910-4f20-8ac7-c5706f93d318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425a593-b08c-42c9-b1cd-1e803ebfcefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a4ab6-dee4-41d5-a639-4ecb15cc56ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
