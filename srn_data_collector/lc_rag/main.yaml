result_path: "results"
annotation_file: "/home/ppradhan/Documents/srn_recommendations/1eed85a5-b8fe-4403-9e24-f16231daad8e.json"

gpu_configs:
  local_inference:
    env_variables:
      CMAKE_ARGS: "-DLLAMA_BLAS=on -DLLAMA_BLAS_VENDOR=OpenBLAS"
      FORCE_CMAKE: "1"

prompt_config:
  prompt_dir: "prompts"
  prompt_iu: "esrs_sys_msg.prompt"


retriever_config:
#  - type: cosine-retriever # langchain in-built
#    file_path: "/home/ppradhan/Documents/srn_raw_json/864f83e0-41d4-4784-899e-1d1212c45371.json"
#    jq_schema: '.doc_data[]'
#    text_content: False
#    content_key: 'text'
#    search__topk: 10
   - type: wali-ml
     debug_doc:
       top_n: 3
       total_top_n: 20
       path: "/home/ppradhan/Documents/srn_recommendations/1eed85a5-b8fe-4403-9e24-f16231daad8e.json"
     doc_batch:
       path: "/home/ppradhan/Documents/srn_recommendations"

lang_chain_config:
  enable_langsmith_tracing: True
  model_config:
    - type: "gpt"
      name: "gpt-3.5-turbo"
      model_name: "gpt-3.5-turbo"
      temperature: 0
    # - type: "llama"
    #   name: "llama-2-70b-chat.Q3_K_L.gguf"
    #   model_path: "/cluster/home/repo/my_llm_experiments/llama-weights/70B/llama-2-70b-chat.Q3_K_L.gguf"
    #   n_gpu_layers: -1
    #   n_batch: 512
    #   n_ctx: 5000
    #   f16_kv: True
    #   verbose: True
    #   temperature: 0

annotation_storage_config:
  sqlite_db: "/home/ppradhan/Documents/my_learnings/llm_tuts/main.db"
