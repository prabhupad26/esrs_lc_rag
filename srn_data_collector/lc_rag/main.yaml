result_path: "/root/repo/esrs_lc_rag/srn_data_collector/lc_rag/results/"
annotation_file: "/root/repo/data/srn_recommendations/3023e67b-bfb2-4886-bcfb-7650c1e6b024.json"
annotation_files: "/root/repo/data/srn_recommendations/"

gpu_configs:
  local_inference:
    env_variables:
      CMAKE_ARGS: "-DLLAMA_BLAS=on -DLLAMA_BLAS_VENDOR=OpenBLAS"
      FORCE_CMAKE: "1"

prompt_config:
  prompt_dir: "/root/repo/esrs_lc_rag/srn_data_collector/lc_rag/prompts"
  prompt_iu: "esrs_sys_msg.prompt"


retriever_config:
 - type: cosine-retriever # langchain in-built
   file_path: "/root/repo/data/srn_raw_json/"
   jq_schema: '.doc_data[]'
   text_content: False
   content_key: 'text'
   search__topk: 20
  #  - type: wali-ml
  #    debug_doc:
  #      top_n: 5
  #      total_top_n: 20
  #      path: "/root/repo/data/srn_recommendations/3023e67b-bfb2-4886-bcfb-7650c1e6b024.json"
  #    doc_batch:
  #      path: "/root/repo/data/srn_recommendations/"

lang_chain_config:
  enable_langsmith_tracing: True

model_config:
  - type: "gpt"
    name: "gpt-3.5-turbo_top20" #"gpt-4"
    model_name: "gpt-3.5-turbo" # "gpt-4"
    temperature: 0
  # - type: "llama"
  #   name: llama-2-70b-chat.Q3_K_L.gguf_ptype_1 #"llama-2-7b-chat.Q3_K_L.gguf" # "llama-2-70b-chat.Q3_K_L.gguf", llama-2-70b-chat.Q3_K_L.gguf, 
  #   model_path: "/scratch/llama_models/llama-2-70b-chat.Q3_K_L.gguf"
  #   n_gpu_layers: -1
  #   n_batch: 512
  #   n_ctx: 10000
  #   f16_kv: True
  #   verbose: True
  #   temperature: 0

annotation_storage_config:
  sqlite_db: "/scratch/main.db"
